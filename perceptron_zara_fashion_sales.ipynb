{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Perceptron (Keras) — Zara Fashion Sales (Kaggle)\n",
        "\n",
        "**Autor:** Nicollas Isaac Queiroz Batista\n",
        "**Data:** 2025-08-17\n",
        "\n",
        "## Objetivo\n",
        "Treinar um **Perceptron** (um modelo de rede neural de camada única) em Keras para uma tarefa **binária** usando o dataset\n",
        "**Zara Fashion Sales Dataset and Report** (Kaggle). O Perceptron, na prática, se comporta como uma **regressão logística** quando usamos uma única camada `Dense(1, activation=\"sigmoid\")` — o que fornece uma **fronteira de decisão linear**. \n",
        "\n",
        "---\n",
        "\n",
        "## Sobre o dataset \n",
        "Este conjunto reúne informações de produtos de moda vendidos pela Zara, incluindo **promoções**, **categorias**, **sazonalidade**, **volume de vendas**, **marca**, **preços** e metadados de coleta. Embora o número de linhas informado no Kaggle seja relativamente modesto (≈226 entradas), o **mix de colunas categóricas e numéricas**, além de possíveis **valores ausentes**, **skews** e **colinearidades** (ex.: preço, promoção, categoria) traz desafios reais para um modelo **linear** como o Perceptron.\n",
        "\n",
        "**Campos esperados (amostra não exaustiva):**\n",
        "- `promotion`, `Product Category`, `Seasonal`\n",
        "- `Sales volume`, `brand`, `section`\n",
        "- `Final price`, `Currency`\n",
        "- `scraped Date`, `name`, `description` (podem conter lacunas/ruídos)\n",
        "\n",
        "**Tarefa de classificação escolhida:** criar um rótulo binário **`high_revenue`** (1/0), onde `revenue = Final price * Sales volume`, e `high_revenue = 1` se `revenue` estiver **acima da mediana** do conjunto.  \n",
        "Isso evita leakings óbvios (ex.: prever `promotion` a partir da própria presença de promoção) e cria uma tarefa de negócio plausível: **identificar produtos de alta receita** com base em atributos observáveis.\n",
        "\n",
        "> **Observação importante:** por ser uma **fronteira de decisão linear**, o Perceptron serve como **baseline**. Espera-se desempenho modesto, pois relações não lineares (ex.: interações entre sazonalidade, categoria e preço) são comuns em varejo. Melhorias são discutidas ao final."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1) Setup e Carregamento de Dados\n",
        "\n",
        "A seguir, usamos [`kagglehub`](https://github.com/Kaggle/kagglehub) para carregar o CSV diretamente do Kaggle.  \n",
        "> **Dica:** Antes, configure suas credenciais do Kaggle (`~/.kaggle/kaggle.json`) ou siga as instruções do `kagglehub`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [
        {
          "ename": "ModuleNotFoundError",
          "evalue": "No module named 'tensorflow'",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "Cell \u001b[1;32mIn[1], line 12\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mpd\u001b[39;00m\n\u001b[0;32m     11\u001b[0m \u001b[38;5;66;03m# Keras / TensorFlow\u001b[39;00m\n\u001b[1;32m---> 12\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mtf\u001b[39;00m\n\u001b[0;32m     13\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m keras\n\u001b[0;32m     14\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mkeras\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m layers\n",
            "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'tensorflow'"
          ]
        }
      ],
      "source": [
        "# Se necessário, instale dependências no seu ambiente local:\n",
        "# !pip install -q kagglehub[pandas-datasets] pandas numpy scikit-learn tensorflow\n",
        "# (Opcional) Para limpar avisos menos relevantes\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "import os\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "# Keras / TensorFlow\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "\n",
        "# Métricas de avaliação (pós-treino)\n",
        "from sklearn.metrics import accuracy_score, f1_score, classification_report, confusion_matrix\n",
        "\n",
        "# Reprodutibilidade\n",
        "SEED = 42\n",
        "np.random.seed(SEED)\n",
        "tf.random.set_seed(SEED)\n",
        "\n",
        "import kagglehub\n",
        "from kagglehub import KaggleDatasetAdapter\n",
        "\n",
        "# Caminho do arquivo dentro do dataset Kaggle (ajuste se necessário após inspecionar a pasta)\n",
        "# O dataset fornece um CSV; vamos tentar detectar automaticamente.\n",
        "# Se souber o nome exato do CSV, defina aqui (ex.: \"zara_fashion.csv\").\n",
        "file_path = \"\"\n",
        "\n",
        "df = kagglehub.load_dataset(\n",
        "    KaggleDatasetAdapter.PANDAS,\n",
        "    \"mohanz123/zara-fashion-sales-dataset-and-report\",\n",
        "    file_path,\n",
        ")\n",
        "\n",
        "print(\"Dimensões:\", df.shape)\n",
        "print(df.head(3))\n",
        "print(\"\\nColunas:\", df.columns.tolist())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2) Exploração inicial (EDA enxuta)\n",
        "\n",
        "Verificamos: dimensões, tipos de dados, amostras, nulos e distribuição de algumas variáveis-chave."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Tipos e nulos\n",
        "display(df.info())\n",
        "print(\"\\nNulos por coluna:\")\n",
        "print(df.isna().sum().sort_values(ascending=False))\n",
        "\n",
        "# Amostras aleatórias\n",
        "display(df.sample(min(5, len(df)), random_state=SEED))\n",
        "\n",
        "# Estatísticas de colunas numéricas\n",
        "display(df.select_dtypes(include=[np.number]).describe().T)\n",
        "\n",
        "# Distribuições úteis (se existirem as colunas esperadas)\n",
        "for col in [\"promotion\", \"Product Category\", \"Seasonal\", \"brand\", \"section\", \"Currency\"]:\n",
        "    if col in df.columns:\n",
        "        print(f\"\\nValue counts — {col}:\")\n",
        "        print(df[col].value_counts(dropna=False).head(10))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3) Criação do alvo binário `high_revenue`\n",
        "\n",
        "- Calculamos `revenue = Final price * Sales volume` (tratando ausências/strings).\n",
        "- Definimos `high_revenue = 1` se `revenue` for **maior que a mediana** do conjunto; caso contrário, `0`.\n",
        "\n",
        "> Essa estratégia torna a tarefa menos trivial e mais próxima de um problema real de **ranking/propensão**."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Cópia de trabalho\n",
        "data = df.copy()\n",
        "\n",
        "# Normalização de nomes esperados\n",
        "# Tentamos mapear variações de capitalização/espaços para garantir robustez.\n",
        "def normalize_cols(cols):\n",
        "    return {c: c.strip().lower().replace(\"  \", \" \").replace(\" \", \"_\") for c in cols}\n",
        "\n",
        "rename_map = normalize_cols(data.columns)\n",
        "data.rename(columns=rename_map, inplace=True)\n",
        "\n",
        "# Possíveis nomes esperados\n",
        "price_cols = [c for c in data.columns if \"final\" in c and \"price\" in c]\n",
        "vol_cols = [c for c in data.columns if \"sales\" in c and \"volume\" in c]\n",
        "\n",
        "if not price_cols or not vol_cols:\n",
        "    raise ValueError(\n",
        "        f\"Não encontrei colunas para preço/volume. Preço detectado: {price_cols}, Volume detectado: {vol_cols}. \"\n",
        "        \"Verifique o nome exato das colunas no CSV e ajuste o código.\"\n",
        "    )\n",
        "\n",
        "price_col = price_cols[0]\n",
        "vol_col = vol_cols[0]\n",
        "\n",
        "# Coerção para numérico\n",
        "data[price_col] = pd.to_numeric(data[price_col], errors=\"coerce\")\n",
        "data[vol_col]   = pd.to_numeric(data[vol_col], errors=\"coerce\")\n",
        "\n",
        "# Remover linhas sem preço/volume\n",
        "data = data.dropna(subset=[price_col, vol_col]).copy()\n",
        "\n",
        "# Receita\n",
        "data[\"revenue\"] = data[price_col] * data[vol_col]\n",
        "\n",
        "# Alvo binário por mediana\n",
        "median_rev = data[\"revenue\"].median()\n",
        "data[\"high_revenue\"] = (data[\"revenue\"] > median_rev).astype(int)\n",
        "\n",
        "print(\"Mediana de receita:\", median_rev)\n",
        "print(\"Balanceamento do alvo:\")\n",
        "print(data[\"high_revenue\"].value_counts(normalize=True).rename({0:\"classe 0\", 1:\"classe 1\"}))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 4) Seleção de features e pré-processamento\n",
        "\n",
        "- **Entrada X:**\n",
        "  - Numéricas: preço, volume e outras numéricas disponíveis.\n",
        "  - Categóricas: `Product Category`, `Seasonal`, `brand`, `section`, `Currency` etc. (one-hot encoding).\n",
        "- **Saída y:** `high_revenue` (0/1).\n",
        "\n",
        "> O Perceptron exige features **numéricas**. Logo, convertemos as categóricas via **one-hot**. Opcionalmente padronizamos com `StandardScaler` para facilitar a otimização do `adam`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.pipeline import Pipeline\n",
        "\n",
        "target = \"high_revenue\"\n",
        "\n",
        "# Separar numéricas e categóricas\n",
        "numeric_cols = data.select_dtypes(include=[np.number]).columns.tolist()\n",
        "# remover colunas que não devem ir para X\n",
        "for drop_col in [target, \"revenue\"]:\n",
        "    if drop_col in numeric_cols:\n",
        "        numeric_cols.remove(drop_col)\n",
        "\n",
        "categorical_cols = data.select_dtypes(exclude=[np.number]).columns.tolist()\n",
        "\n",
        "print(\"Numéricas:\", numeric_cols[:10], \"...\")\n",
        "print(\"Categóricas:\", categorical_cols[:10], \"...\")\n",
        "\n",
        "X = data[numeric_cols + categorical_cols].copy()\n",
        "y = data[target].copy()\n",
        "\n",
        "# Treino/teste estratificado\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y, test_size=0.2, random_state=SEED, stratify=y\n",
        ")\n",
        "\n",
        "# Transformador de colunas\n",
        "numeric_transformer = Pipeline(steps=[\n",
        "    (\"scaler\", StandardScaler())\n",
        "])\n",
        "\n",
        "categorical_transformer = Pipeline(steps=[\n",
        "    (\"onehot\", OneHotEncoder(handle_unknown=\"ignore\", sparse_output=False))\n",
        "])\n",
        "\n",
        "preprocess = ColumnTransformer(\n",
        "    transformers=[\n",
        "        (\"num\", numeric_transformer, numeric_cols),\n",
        "        (\"cat\", categorical_transformer, categorical_cols)\n",
        "    ]\n",
        ")\n",
        "\n",
        "# Ajuste e transformação\n",
        "X_train_proc = preprocess.fit_transform(X_train)\n",
        "X_test_proc  = preprocess.transform(X_test)\n",
        "\n",
        "print(\"Shape X_train_proc:\", X_train_proc.shape)\n",
        "print(\"Shape X_test_proc:\", X_test_proc.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 5) Modelo Perceptron (Keras)\n",
        "\n",
        "- **Arquitetura:** `Sequential([Dense(1, activation=\"sigmoid\")])`\n",
        "- **Otimizador:** `adam` — adapta taxas de aprendizado por parâmetro.\n",
        "- **Loss:** `binary_crossentropy` — apropriada para classificação binária com `sigmoid`.\n",
        "- **Métricas:** `accuracy` e **F1** (calculada após o treino com `sklearn` para robustez).\n",
        "\n",
        "> Por ser apenas uma camada `Dense` com `sigmoid`, o modelo aprende um **hiperplano**: é o baseline mais simples e interpretável."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Construção do Perceptron\n",
        "model = keras.Sequential([\n",
        "    layers.Input(shape=(X_train_proc.shape[1],)),\n",
        "    layers.Dense(1, activation=\"sigmoid\")\n",
        "])\n",
        "\n",
        "model.compile(\n",
        "    optimizer=\"adam\",\n",
        "    loss=\"binary_crossentropy\",\n",
        "    metrics=[\"accuracy\"]\n",
        ")\n",
        "\n",
        "model.summary()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 6) Treinamento\n",
        "\n",
        "Treinamos por **50 épocas** com **batch_size=10**. Mantemos um `validation_split=0.2` apenas no conjunto de treino para monitorar overfitting."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "history = model.fit(\n",
        "    X_train_proc, y_train.values,\n",
        "    epochs=50,\n",
        "    batch_size=10,\n",
        "    validation_split=0.2,\n",
        "    verbose=0\n",
        ")\n",
        "\n",
        "# Curvas (opcional)\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.figure()\n",
        "plt.plot(history.history[\"loss\"], label=\"loss\")\n",
        "plt.plot(history.history[\"val_loss\"], label=\"val_loss\")\n",
        "plt.xlabel(\"Epoch\")\n",
        "plt.ylabel(\"Binary Crossentropy\")\n",
        "plt.legend()\n",
        "plt.title(\"Curva de perda\")\n",
        "plt.show()\n",
        "\n",
        "plt.figure()\n",
        "plt.plot(history.history[\"accuracy\"], label=\"acc\")\n",
        "plt.plot(history.history[\"val_accuracy\"], label=\"val_acc\")\n",
        "plt.xlabel(\"Epoch\")\n",
        "plt.ylabel(\"Accuracy\")\n",
        "plt.legend()\n",
        "plt.title(\"Curva de acurácia\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 7) Avaliação no conjunto de teste\n",
        "\n",
        "Geramos `y_pred` com `model.predict`, binarizamos com threshold padrão **0.5** e calculamos **Accuracy** e **F1**. \n",
        "Também exibimos **matriz de confusão** e `classification_report` para diagnóstico."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Predição\n",
        "y_prob = model.predict(X_test_proc).ravel()\n",
        "y_pred = (y_prob >= 0.5).astype(int)\n",
        "\n",
        "acc = accuracy_score(y_test, y_pred)\n",
        "f1  = f1_score(y_test, y_pred, zero_division=0)\n",
        "\n",
        "print(f\"Test Accuracy: {acc:.4f}\")\n",
        "print(f\"Test F1:       {f1:.4f}\")\n",
        "print(\"\\nMatriz de confusão:\")\n",
        "print(confusion_matrix(y_test, y_pred))\n",
        "print(\"\\nClassification report:\")\n",
        "print(classification_report(y_test, y_pred, zero_division=0))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 8) Interpretação dos resultados\n",
        "\n",
        "- **O que observar:** dado que o Perceptron usa **fronteira linear**, métricas medianas são esperadas quando a relação entre atributos e o rótulo é **não linear**.\n",
        "- **Se F1 < Accuracy:** pode indicar **desbalanceamento** entre classes; o F1 pondera melhor **precisão/recall** para a classe positiva.\n",
        "- **Curvas de validação:** divergência entre `loss` e `val_loss` sugere **overfitting**; use regularização ou menos features ruidosas.\n",
        "\n",
        "### Possíveis Melhorias\n",
        "1. **Engenharia de features:** interações (ex.: `price x seasonal`), bins de preço/volume, features de texto (TF‑IDF em `description`, `name`).  \n",
        "2. **Tratamento de desbalanceamento:** `class_weight` no `model.fit` ou técnicas de amostragem (SMOTE).  \n",
        "3. **Modelo não linear:** adicionar camadas ocultas (MLP) ou tentar árvores/boosting para capturar interações.  \n",
        "4. **Validação robusta:** K‑fold estratificado e busca de hiperparâmetros.  \n",
        "5. **Limpeza de dados:** remover outliers extremos e padronizar moedas/unidades.\n",
        "\n",
        "> **Nota:** como baseline, o Perceptron é valioso pela **simplicidade** e por servir de **referência** para medir ganhos reais de modelos mais complexos."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 9) (Opcional) Exportar arrays pré-processados\n",
        "\n",
        "Caso queira treinar outros modelos rapidamente, é útil salvar `X_train_proc`, `X_test_proc`, `y_train`, `y_test`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Salvar localmente (opcional)\n",
        "# np.save(\"X_train_proc.npy\", X_train_proc)\n",
        "# np.save(\"X_test_proc.npy\", X_test_proc)\n",
        "# y_train.to_csv(\"y_train.csv\", index=False)\n",
        "# y_test.to_csv(\"y_test.csv\", index=False)"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "nome_do_seu_projeto",
      "language": "python",
      "name": "nome_do_seu_projeto"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.7"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
